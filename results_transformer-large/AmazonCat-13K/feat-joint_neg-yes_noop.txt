Namespace(ensemble=True, input_inst_label='datasets/AmazonCat-13K/Y.tst.npz', pred_path=['pretrained_models/AmazonCat-13K/pifa-a5-s0/ranker_bert-large-cased-whole-word-masking_seq-128/tst.pred.npz', 'pretrained_models/AmazonCat-13K/pifa-a5-s0/ranker_roberta-large_seq-128/tst.pred.npz', 'pretrained_models/AmazonCat-13K/pifa-a5-s0/ranker_xlnet-large-cased_seq-128/tst.pred.npz', 'pretrained_models/AmazonCat-13K/pifa-neural-a5-s0/ranker_bert-large-cased-whole-word-masking_seq-128/tst.pred.npz', 'pretrained_models/AmazonCat-13K/pifa-neural-a5-s0/ranker_roberta-large_seq-128/tst.pred.npz', 'pretrained_models/AmazonCat-13K/pifa-neural-a5-s0/ranker_xlnet-large-cased_seq-128/tst.pred.npz', 'pretrained_models/AmazonCat-13K/text-emb-a5-s0/ranker_bert-large-cased-whole-word-masking_seq-128/tst.pred.npz', 'pretrained_models/AmazonCat-13K/text-emb-a5-s0/ranker_roberta-large_seq-128/tst.pred.npz', 'pretrained_models/AmazonCat-13K/text-emb-a5-s0/ranker_xlnet-large-cased_seq-128/tst.pred.npz'])
==== Evaluation on pretrained_models/AmazonCat-13K/pifa-a5-s0/ranker_bert-large-cased-whole-word-masking_seq-128/tst.pred.npz
prec   = 95.84 89.89 82.56 75.26 67.32 59.97 53.89 48.81 44.58 40.99
recall = 27.31 48.10 62.44 72.51 78.34 81.70 84.05 85.73 87.03 88.04
==== Evaluation on pretrained_models/AmazonCat-13K/pifa-a5-s0/ranker_roberta-large_seq-128/tst.pred.npz
prec   = 96.07 90.09 82.83 75.53 67.59 60.24 54.13 49.04 44.80 41.20
recall = 27.38 48.18 62.60 72.73 78.62 82.05 84.41 86.12 87.45 88.50
==== Evaluation on pretrained_models/AmazonCat-13K/pifa-a5-s0/ranker_xlnet-large-cased_seq-128/tst.pred.npz
prec   = 96.00 90.10 82.83 75.56 67.62 60.25 54.14 49.07 44.82 41.23
recall = 27.35 48.19 62.61 72.74 78.65 82.05 84.40 86.13 87.45 88.50
==== Evaluation on pretrained_models/AmazonCat-13K/pifa-neural-a5-s0/ranker_bert-large-cased-whole-word-masking_seq-128/tst.pred.npz
prec   = 95.79 89.99 82.53 75.18 67.22 59.88 53.77 48.70 44.45 40.87
recall = 27.31 48.25 62.46 72.45 78.25 81.60 83.90 85.58 86.84 87.85
==== Evaluation on pretrained_models/AmazonCat-13K/pifa-neural-a5-s0/ranker_roberta-large_seq-128/tst.pred.npz
prec   = 96.07 90.21 82.78 75.44 67.46 60.10 53.99 48.91 44.67 41.08
recall = 27.40 48.35 62.62 72.68 78.51 81.89 84.23 85.92 87.23 88.25
==== Evaluation on pretrained_models/AmazonCat-13K/pifa-neural-a5-s0/ranker_xlnet-large-cased_seq-128/tst.pred.npz
prec   = 96.01 90.22 82.81 75.51 67.55 60.19 54.08 49.00 44.75 41.16
recall = 27.37 48.35 62.63 72.72 78.57 81.97 84.30 86.02 87.33 88.37
==== Evaluation on pretrained_models/AmazonCat-13K/text-emb-a5-s0/ranker_bert-large-cased-whole-word-masking_seq-128/tst.pred.npz
prec   = 95.80 90.16 82.68 75.24 67.12 59.67 53.50 48.39 44.12 40.50
recall = 27.29 48.41 62.64 72.56 78.18 81.38 83.56 85.12 86.28 87.15
==== Evaluation on pretrained_models/AmazonCat-13K/text-emb-a5-s0/ranker_roberta-large_seq-128/tst.pred.npz
prec   = 96.11 90.44 83.01 75.57 67.44 59.96 53.78 48.66 44.38 40.75
recall = 27.40 48.55 62.86 72.85 78.53 81.76 83.96 85.55 86.75 87.65
==== Evaluation on pretrained_models/AmazonCat-13K/text-emb-a5-s0/ranker_xlnet-large-cased_seq-128/tst.pred.npz
prec   = 95.99 90.33 82.88 75.47 67.36 59.91 53.75 48.65 44.37 40.74
recall = 27.35 48.47 62.76 72.75 78.44 81.68 83.90 85.50 86.70 87.60
==== Evaluations of Ensembles of All Predictions ====
ens: average
prec   = 96.65 91.05 83.74 76.44 68.42 61.00 54.84 49.74 45.47 41.85
recall = 27.60 48.83 63.35 73.58 79.51 82.96 85.37 87.16 88.55 89.66
ens: rank_average
prec   = 96.59 90.95 83.65 76.36 68.38 60.99 54.85 49.74 45.46 41.83
recall = 27.57 48.74 63.27 73.51 79.49 82.98 85.42 87.20 88.58 89.67
ens: round_robin
prec   = 95.84 89.95 82.74 75.48 67.60 60.33 54.26 49.22 45.00 41.44
recall = 27.31 48.19 62.70 72.88 78.86 82.38 84.82 86.62 88.02 89.14
