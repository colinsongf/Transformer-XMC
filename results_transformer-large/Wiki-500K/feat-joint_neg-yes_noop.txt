Namespace(ensemble=True, input_inst_label='datasets/Wiki-500K/Y.tst.npz', pred_path=['pretrained_models/Wiki-500K/pifa-a5-s0/ranker_bert-large-cased-whole-word-masking_seq-128/tst.pred.npz', 'pretrained_models/Wiki-500K/pifa-a5-s0/ranker_roberta-large_seq-128/tst.pred.npz', 'pretrained_models/Wiki-500K/pifa-a5-s0/ranker_xlnet-large-cased_seq-128/tst.pred.npz', 'pretrained_models/Wiki-500K/pifa-neural-a5-s0/ranker_bert-large-cased-whole-word-masking_seq-128/tst.pred.npz', 'pretrained_models/Wiki-500K/pifa-neural-a5-s0/ranker_roberta-large_seq-128/tst.pred.npz', 'pretrained_models/Wiki-500K/pifa-neural-a5-s0/ranker_xlnet-large-cased_seq-128/tst.pred.npz', 'pretrained_models/Wiki-500K/text-emb-a5-s0/ranker_bert-large-cased-whole-word-masking_seq-128/tst.pred.npz', 'pretrained_models/Wiki-500K/text-emb-a5-s0/ranker_roberta-large_seq-128/tst.pred.npz', 'pretrained_models/Wiki-500K/text-emb-a5-s0/ranker_xlnet-large-cased_seq-128/tst.pred.npz'])
==== Evaluation on pretrained_models/Wiki-500K/pifa-a5-s0/ranker_bert-large-cased-whole-word-masking_seq-128/tst.pred.npz
prec   = 75.46 63.55 54.44 47.57 42.16 37.82 34.25 31.26 28.72 26.53
recall = 24.96 37.74 45.18 50.10 53.57 56.14 58.09 59.60 60.78 61.69
==== Evaluation on pretrained_models/Wiki-500K/pifa-a5-s0/ranker_roberta-large_seq-128/tst.pred.npz
prec   = 76.14 64.22 55.05 48.10 42.64 38.23 34.63 31.61 29.03 26.81
recall = 25.22 38.18 45.69 50.69 54.20 56.79 58.77 60.29 61.47 62.39
==== Evaluation on pretrained_models/Wiki-500K/pifa-a5-s0/ranker_xlnet-large-cased_seq-128/tst.pred.npz
prec   = 76.02 64.17 55.07 48.14 42.72 38.34 34.73 31.70 29.13 26.91
recall = 25.17 38.15 45.71 50.73 54.30 56.95 58.93 60.47 61.67 62.60
==== Evaluation on pretrained_models/Wiki-500K/pifa-neural-a5-s0/ranker_bert-large-cased-whole-word-masking_seq-128/tst.pred.npz
prec   = 75.49 63.83 54.78 47.88 42.44 38.06 34.44 31.43 28.86 26.65
recall = 24.98 37.93 45.46 50.42 53.91 56.49 58.43 59.94 61.12 62.02
==== Evaluation on pretrained_models/Wiki-500K/pifa-neural-a5-s0/ranker_roberta-large_seq-128/tst.pred.npz
prec   = 76.35 64.72 55.55 48.55 43.05 38.59 34.94 31.88 29.27 27.02
recall = 25.28 38.42 46.03 51.06 54.59 57.18 59.16 60.68 61.87 62.78
==== Evaluation on pretrained_models/Wiki-500K/pifa-neural-a5-s0/ranker_xlnet-large-cased_seq-128/tst.pred.npz
prec   = 75.84 64.28 55.20 48.26 42.79 38.37 34.74 31.69 29.10 26.87
recall = 25.11 38.24 45.84 50.87 54.40 57.00 58.97 60.49 61.67 62.58
==== Evaluation on pretrained_models/Wiki-500K/text-emb-a5-s0/ranker_bert-large-cased-whole-word-masking_seq-128/tst.pred.npz
prec   = 73.71 61.84 52.68 45.81 40.47 36.20 32.71 29.79 27.29 25.11
recall = 24.41 36.85 43.89 48.49 51.68 54.02 55.79 57.13 58.15 58.90
==== Evaluation on pretrained_models/Wiki-500K/text-emb-a5-s0/ranker_roberta-large_seq-128/tst.pred.npz
prec   = 74.46 62.48 53.17 46.19 40.77 36.45 32.92 29.96 27.44 25.24
recall = 24.57 37.03 44.03 48.59 51.77 54.11 55.88 57.22 58.23 58.97
==== Evaluation on pretrained_models/Wiki-500K/text-emb-a5-s0/ranker_xlnet-large-cased_seq-128/tst.pred.npz
prec   = 74.55 62.69 53.46 46.49 41.07 36.75 33.21 30.24 27.71 25.49
recall = 24.65 37.24 44.37 49.02 52.27 54.66 56.48 57.85 58.89 59.65
==== Evaluations of Ensembles of All Predictions ====
ens: average
prec   = 78.33 67.10 58.12 51.20 45.69 41.20 37.49 34.38 31.73 29.43
recall = 26.06 40.06 48.46 54.22 58.42 61.61 64.12 66.15 67.82 69.21
ens: rank_average
prec   = 78.19 67.13 58.26 51.35 45.84 41.33 37.58 34.43 31.73 29.39
recall = 25.98 40.08 48.61 54.44 58.69 61.88 64.34 66.31 67.90 69.21
ens: round_robin
prec   = 75.46 64.16 55.46 48.85 43.60 39.34 35.81 32.88 30.39 28.25
recall = 24.96 38.34 46.46 52.10 56.22 59.34 61.81 63.84 65.53 66.98
